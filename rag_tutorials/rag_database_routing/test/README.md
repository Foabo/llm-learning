# RAG数据库路由系统 - 测试套件

本测试套件为RAG数据库路由系统提供全面的功能测试，确保各个模块正常工作。

## 📁 测试结构

```
test/
├── __init__.py              # 测试模块初始化
├── test_models.py           # 模型和配置测试
├── test_tools.py            # 工具组件测试
├── test_agents.py           # 智能代理测试
├── test_workflow.py         # LangGraph工作流测试
├── run_all_tests.py         # 完整测试套件运行器
└── README.md               # 本文档
```

## 🧪 测试模块说明

### 1. 模型测试 (`test_models.py`)

测试以下组件：
- **配置加载**: 验证环境变量和设置加载
- **LLM初始化**: 测试OpenAI和模拟LLM
- **Embeddings**: 测试OpenAI和豆包embedding
- **豆包专项**: 测试豆包多模态embedding API

**运行方式**:
```bash
uv run python test/test_models.py
```

### 2. 工具测试 (`test_tools.py`)

测试以下组件：
- **向量存储**: Qdrant集合创建、文档添加、相似性搜索
- **文档处理**: 文本分割、文件类型检测
- **网络搜索**: 搜索功能和结果格式化
- **工具集成**: 完整的文档处理到检索流程

**运行方式**:
```bash
uv run python test/test_tools.py
```

### 3. 代理测试 (`test_agents.py`)

测试以下组件：
- **路由代理**: 问题分类和数据库路由
- **问答代理**: 基于上下文的答案生成
- **代理集成**: 完整的路由+检索+问答流程
- **提示词模板**: 模板加载和变量替换

**运行方式**:
```bash
uv run python test/test_agents.py
```

### 4. 工作流测试 (`test_workflow.py`)

测试以下组件：
- **工作流状态**: LangGraph状态管理
- **工作流节点**: 各个处理节点功能
- **工作流图**: 完整流程图编译和运行
- **条件判断**: 流程分支逻辑
- **性能测试**: 执行时间统计

**运行方式**:
```bash
uv run python test/test_workflow.py
```

## 🚀 快速开始

### 运行所有测试

```bash
# 进入项目目录
cd rag_database_routing

# 运行完整测试套件
uv run python test/run_all_tests.py
```

### 运行单个测试模块

```bash
# 测试模型组件
uv run python test/test_models.py

# 测试工具组件
uv run python test/test_tools.py

# 测试代理组件  
uv run python test/test_agents.py

# 测试工作流
uv run python test/test_workflow.py
```

## 📊 测试输出示例

### 成功输出
```
🧪 RAG数据库路由系统 - 完整测试套件
============================================================
开始时间: 2024-01-15 10:30:00

🚀 开始测试: 模型测试
============================================================
🧪 测试配置加载
========================================
✅ 配置加载成功
   OpenAI API Key: 已设置
   ARK API Key: 已设置
   ...

📊 测试结果总汇
============================================================
模型测试        | ✅ 通过   |   2.35s
工具测试        | ✅ 通过   |   3.42s  
代理测试        | ✅ 通过   |   1.89s
工作流测试      | ✅ 通过   |   4.15s
------------------------------------------------------------
总计: 4 个模块
通过: 4 个
失败: 0 个
通过率: 100.0%
总耗时: 11.81s
```

### 失败输出
```
❌ 模型测试失败: 配置加载失败: Invalid API key

⚠️ 结论: 1 个模块测试失败，需要修复后再使用。

常见问题解决方案：
   • 检查 .env 文件中的API密钥配置
   • 确认网络连接正常
   • 验证Qdrant服务可访问
```

## ⚙️ 测试配置

### 环境要求

1. **环境变量**: 确保 `.env` 文件配置正确
   ```bash
   # 复制配置模板
   cp .env.example .env
   
   # 编辑配置
   nano .env
   ```

2. **依赖安装**: 确保所有依赖已安装
   ```bash
   uv sync
   ```

3. **服务运行**: 确保Qdrant服务可访问
   ```bash
   # 检查Qdrant连接
   curl http://localhost:6333/collections
   ```

### 模拟模式

测试套件支持模拟模式，无需真实API即可测试：

- **模拟LLM**: 当OpenAI API不可用时自动启用
- **模拟Embeddings**: 生成随机向量用于测试
- **模拟向量存储**: 内存中的简单向量存储

这确保了即使在没有外部服务的情况下也能进行基本功能测试。

## 🐛 故障排除

### 常见问题

1. **导入错误**
   ```
   ImportError: No module named 'src'
   ```
   **解决方案**: 确保从项目根目录运行测试

2. **API密钥错误**
   ```
   Invalid API key
   ```
   **解决方案**: 检查 `.env` 文件中的API密钥配置

3. **网络连接错误**
   ```
   ConnectionError: Unable to connect to Qdrant
   ```
   **解决方案**: 确认Qdrant服务运行正常或使用模拟模式

4. **依赖版本冲突**
   ```
   VersionConflict: langchain 0.1.0 vs 0.2.0
   ```
   **解决方案**: 重新安装依赖 `uv sync --force`

### 调试模式

在测试脚本中启用详细输出：

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# 然后运行测试
uv run python test/test_models.py
```

## 📈 测试覆盖率

当前测试覆盖的功能：

- ✅ 配置管理 (100%)
- ✅ LLM集成 (95%)
- ✅ Embedding集成 (100%)
- ✅ 向量存储 (90%)
- ✅ 文档处理 (85%)
- ✅ 网络搜索 (80%)
- ✅ 智能代理 (95%)
- ✅ LangGraph工作流 (90%)

## 🔄 持续改进

### 添加新测试

1. 在相应的测试文件中添加测试函数
2. 在 `run_all_tests.py` 中注册新的测试模块
3. 更新本文档说明

### 性能基准

测试套件会记录执行时间，可用于性能基准：

- 模型初始化: < 3s
- 工具测试: < 5s  
- 代理测试: < 3s
- 工作流测试: < 5s
- 总体测试: < 15s

如果超出这些时间，可能需要优化代码或检查系统资源。

## 📞 支持

如果遇到测试相关问题：

1. 查看测试输出中的详细错误信息
2. 检查 `.env` 配置是否正确
3. 确认所有依赖已正确安装
4. 尝试使用模拟模式运行测试
5. 查看项目主文档获取更多帮助

---

*测试是确保代码质量的重要环节，建议在每次重要更改后运行完整测试套件。* 