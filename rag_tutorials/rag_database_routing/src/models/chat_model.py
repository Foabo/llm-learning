"""èŠå¤©æ¨¡å‹é…ç½®å’Œç®¡ç†."""

import os
from functools import lru_cache
from langchain_openai import ChatOpenAI
from .config import settings


@lru_cache(maxsize=1)
def get_chat_model() -> ChatOpenAI:
    """è·å–ç¼“å­˜çš„èŠå¤©æ¨¡å‹å®ä¾‹."""
    
    if not settings.openai_api_key:
        raise ValueError("æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®©ChatOpenAIè‡ªåŠ¨è¯»å–
    os.environ["OPENAI_API_KEY"] = settings.openai_api_key
    if settings.openai_base_url:
        os.environ["OPENAI_BASE_URL"] = settings.openai_base_url
    
    print(f"ğŸ¤– ä½¿ç”¨èŠå¤©æ¨¡å‹: {settings.openai_model}")
    if settings.openai_base_url:
        print(f"ğŸ”— APIç«¯ç‚¹: {settings.openai_base_url}")
    
    return ChatOpenAI(
        model=settings.openai_model,
        temperature=0
    )